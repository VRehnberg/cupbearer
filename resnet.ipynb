{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/Arch/software/tqdm/4.64.1-GCCcore-12.2.0/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from cupbearer import data, detectors, models, scripts, tasks, utils\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a backdoored classifier\n",
    "First, we train a classifier on poisoned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CIFAR10'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.CIFAR10.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.ResnetConfig()\n",
    "Dataset = data.CIFAR10\n",
    "Backdoor = data.WanetBackdoor\n",
    "path = Path(f\"logs/{type(model).__name__}/{Dataset.__name__}/{Backdoor.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-21 17:57:00.748\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mGenerating new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 17:57:00.802\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 17:57:00.804\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mGenerating new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 17:57:00.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 17:57:00.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mGenerating new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 17:57:00.812\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 17:57:00.815\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 17:57:00.817\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-21 17:57:05.158\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mstore\u001b[0m:\u001b[36m172\u001b[0m - \u001b[34m\u001b[1mStoring control grid to logs/ResnetConfig/CIFAR10/WanetBackdoor/wanet_backdoor.pt\u001b[0m\n",
      "/mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbearer-env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbeare ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbearer-env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbeare ...\n",
      "You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbearer-env/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory logs/ResnetConfig/CIFAR10/WanetBackdoor/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | model          | PreActResNet       | 11.2 M\n",
      "1 | train_accuracy | MulticlassAccuracy | 0     \n",
      "2 | val_accuracy   | ModuleList         | 0     \n",
      "3 | test_accuracy  | ModuleList         | 0     \n",
      "------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.685    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbearer-env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 391/391 [00:15<00:00, 25.77it/s, train/loss=1.490]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  3.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  3.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:01<00:00,  3.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  3.00it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  8.70it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:01,  2.61it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:01<00:00,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:02<00:00,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:02<00:00,  1.89it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  8.68it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:01,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:01,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:02<00:00,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 391/391 [00:13<00:00, 28.39it/s, train/loss=1.270]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  3.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  3.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:01<00:00,  3.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  2.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  8.74it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:01,  2.57it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:01<00:00,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:02<00:00,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:02<00:00,  1.87it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  8.69it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:01,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:01,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:02<00:00,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.00it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 391/391 [00:12<00:00, 31.54it/s, train/loss=1.300]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  9.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  5.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  4.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00,  4.13it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  9.01it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:00,  3.61it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:00<00:00,  3.02it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:01<00:00,  2.58it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:01<00:00,  2.58it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  9.03it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:00,  3.14it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.58it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.37it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 391/391 [00:12<00:00, 31.59it/s, train/loss=0.980]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  5.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  4.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00,  4.13it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  8.99it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:00,  3.62it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:00<00:00,  3.02it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:01<00:00,  2.79it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:01<00:00,  2.75it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  8.99it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:00,  3.14it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.58it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.36it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 391/391 [00:12<00:00, 30.83it/s, train/loss=0.760]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  5.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  4.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00,  4.14it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  9.02it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:00,  3.62it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:00<00:00,  3.03it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:01<00:00,  2.79it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:01<00:00,  2.75it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  8.97it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:00,  3.14it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.58it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.37it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 391/391 [00:12<00:00, 31.59it/s, train/loss=0.869]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  9.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  4.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  4.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:01<00:00,  3.70it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  3.74it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  8.99it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:00,  3.60it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:00<00:00,  3.01it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:01<00:00,  2.78it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:01<00:00,  2.74it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  8.99it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:00,  3.14it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.58it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.37it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 391/391 [00:13<00:00, 28.12it/s, train/loss=0.868]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  3.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  3.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:01<00:00,  3.02it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  2.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  8.65it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:01,  2.56it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:01<00:00,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:02<00:00,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:02<00:00,  1.88it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  8.75it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:01,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.04it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 391/391 [00:12<00:00, 30.92it/s, train/loss=0.617]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  5.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  4.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00,  4.13it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  8.98it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:00,  3.63it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:00<00:00,  3.03it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:01<00:00,  2.79it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:01<00:00,  2.75it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  8.98it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:00,  3.12it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.57it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.37it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 391/391 [00:12<00:00, 31.52it/s, train/loss=1.020]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  8.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  3.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  3.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:01<00:00,  3.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  3.00it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  8.74it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:01,  2.62it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:01<00:00,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:01<00:00,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:02<00:00,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  9.04it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:00,  3.16it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.60it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.39it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.34it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 391/391 [00:12<00:00, 31.63it/s, train/loss=0.716]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██        | 1/5 [00:00<00:00,  9.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|████      | 2/5 [00:00<00:00,  5.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████    | 3/5 [00:00<00:00,  4.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████  | 4/5 [00:00<00:00,  4.11it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  4.08it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 1:  20%|██        | 1/5 [00:00<00:00,  9.00it/s]\u001b[A\n",
      "Validation DataLoader 1:  40%|████      | 2/5 [00:00<00:00,  3.62it/s]\u001b[A\n",
      "Validation DataLoader 1:  60%|██████    | 3/5 [00:00<00:00,  3.03it/s]\u001b[A\n",
      "Validation DataLoader 1:  80%|████████  | 4/5 [00:01<00:00,  2.80it/s]\u001b[A\n",
      "Validation DataLoader 1: 100%|██████████| 5/5 [00:01<00:00,  2.76it/s]\u001b[A\n",
      "Validation DataLoader 1:   0%|          | 0/5 [00:00<?, ?it/s]        \u001b[A\n",
      "Validation DataLoader 2:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 2:  20%|██        | 1/5 [00:00<00:00,  9.00it/s]\u001b[A\n",
      "Validation DataLoader 2:  40%|████      | 2/5 [00:00<00:00,  3.16it/s]\u001b[A\n",
      "Validation DataLoader 2:  60%|██████    | 3/5 [00:01<00:00,  2.60it/s]\u001b[A\n",
      "Validation DataLoader 2:  80%|████████  | 4/5 [00:01<00:00,  2.39it/s]\u001b[A\n",
      "Validation DataLoader 2: 100%|██████████| 5/5 [00:02<00:00,  2.34it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 391/391 [00:18<00:00, 21.13it/s, train/loss=0.716]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 391/391 [00:19<00:00, 20.26it/s, train/loss=0.716]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(0.7156),\n",
       " 'train/acc_step': tensor(0.7625),\n",
       " 'clean/loss/dataloader_idx_0': tensor(0.5392),\n",
       " 'clean/acc_step/dataloader_idx_0': tensor(0.8227),\n",
       " 'backdoor/loss/dataloader_idx_1': tensor(0.0016),\n",
       " 'backdoor/acc_step/dataloader_idx_1': tensor(0.9994),\n",
       " 'noisy/loss/dataloader_idx_2': tensor(1.7687),\n",
       " 'noisy/acc_step/dataloader_idx_2': tensor(0.3621),\n",
       " 'clean/acc_epoch': tensor(0.8227),\n",
       " 'backdoor/acc_epoch': tensor(0.9994),\n",
       " 'noisy/acc_epoch': tensor(0.3621),\n",
       " 'train/acc_epoch': tensor(0.7529)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts.train_classifier(\n",
    "    scripts.TrainClassifierConfig(\n",
    "        path=path,\n",
    "        model=model,\n",
    "        train_data=data.BackdoorData(\n",
    "            original=Dataset(),\n",
    "            backdoor=Backdoor(p_backdoor=0.10, p_noise=0.20),\n",
    "        ),\n",
    "        val_data={\n",
    "            \"clean\": Dataset(train=False),\n",
    "            \"backdoor\": data.BackdoorData(\n",
    "                # By default, the poison rate is 100%, so this will let us evaluate\n",
    "                # performance on completely poisoned data\n",
    "                original=Dataset(train=False),\n",
    "                backdoor=Backdoor(),\n",
    "            ),\n",
    "            \"noisy\": data.BackdoorData(\n",
    "                original=Dataset(train=False),\n",
    "                backdoor=Backdoor(p_noise=1, p_backdoor=0),\n",
    "            ),\n",
    "        },\n",
    "        train_config=utils.TrainConfig(\n",
    "            num_epochs=10,\n",
    "            num_workers=4,\n",
    "            pbar=True,\n",
    "            optimizer=utils.OptimizerConfig(\n",
    "                lr=3e-4,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training script will have automatically created Tensorboard log files. The model should be close to perfect on backdoored inputs, and decent (~95%) on clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 448943), started 2:13:31 ago. (Use '!kill 448943' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1ac074ff71c306c8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1ac074ff71c306c8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir logs/demo (started 2:13:32 ago; port 6006, pid 448943).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-432eb5d55ebd96f6\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-432eb5d55ebd96f6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explicitly evaluate the trained model (right now this is pretty limited and doesn't support multiple datasets at once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-21 18:00:42.469\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.scripts.eval_classifier\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mLoading transform: ToTensor()\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbearer-env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbeare ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/mimer/NOBACKUP/groups/ml-safety/vikren/mad/cupbearer-env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  3.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8300999999046326     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/acc_step       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8300999999046326     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5112817287445068     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8300999999046326    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/acc_step      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8300999999046326    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5112817287445068    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scripts.eval_classifier(\n",
    "    scripts.EvalClassifierConfig(\n",
    "        path=path, data=Dataset(train=False)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-21 18:00:46.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mGenerating new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:46.866\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:46.869\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.scripts.eval_classifier\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mLoading transform: ToTensor()\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:46.871\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.scripts.eval_classifier\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mLoading transform: WanetBackdoor(p_backdoor=1.0, target_class=0, p_noise=0.0, control_grid_width=4, warping_strength=0.5, grid_rescale=1.0, _control_grid=([[-0.2654159963130951, -0.8007417917251587, -0.6394952535629272, 0.5390511155128479], [-0.4819018542766571, -0.8012377619743347, -0.19970284402370453, 0.7660093903541565], [0.6346703171730042, -0.5159189701080322, -0.7389646172523499, 0.12375395745038986], [-0.8003342151641846, -0.0015938153956085443, -0.8079965114593506, 0.6781684756278992]], [[0.4791393578052521, -0.589881956577301, 0.2161276936531067, 0.36116501688957214], [-0.2975912392139435, -0.28779086470603943, -0.9498175382614136, 0.24493107199668884], [0.6009668111801147, -0.06403056532144547, 0.6171604990959167, -0.3536461591720581], [0.11236820369958878, -0.5152488350868225, 0.7571988105773926, 0.7579787373542786]]))\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:46.872\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m177\u001b[0m - \u001b[34m\u001b[1mLoading control grid from logs/ResnetConfig/CIFAR10/WanetBackdoor/wanet_backdoor.pt\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:46.876\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:02<00:00,  2.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1965000033378601     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/acc_step       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1965000033378601     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    3.1410634517669678     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1965000033378601    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/acc_step      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1965000033378601    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   3.1410634517669678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scripts.eval_classifier(\n",
    "    scripts.EvalClassifierConfig(\n",
    "        path=path, data=data.BackdoorData(\n",
    "            original=Dataset(train=False),\n",
    "            backdoor=Backdoor(),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-21 18:00:51.070\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mGenerating new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:51.072\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:51.075\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.scripts.eval_classifier\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mLoading transform: ToTensor()\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:51.076\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.scripts.eval_classifier\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mLoading transform: WanetBackdoor(p_backdoor=0, target_class=0, p_noise=1, control_grid_width=4, warping_strength=0.5, grid_rescale=1.0, _control_grid=([[0.48124271631240845, -0.8087896108627319, -0.45163992047309875, -0.43014565110206604], [0.3139922022819519, -1.1025198698043823, -0.08548571914434433, -1.0263582468032837], [0.14322981238365173, 0.14262735843658447, 0.03894158825278282, 0.6163105964660645], [-0.2138892412185669, -0.7651118040084839, -0.39760857820510864, -0.7512485384941101]], [[-1.1378183364868164, 0.45696842670440674, 0.25145405530929565, -0.8991430401802063], [0.12741325795650482, 0.011784249916672707, 0.6435214877128601, 0.08128483593463898], [1.1853253841400146, 0.13031163811683655, 0.24896150827407837, -0.8818793296813965], [-0.40784117579460144, -0.5924900770187378, 0.4964540898799896, -0.67820805311203]]))\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:51.077\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m177\u001b[0m - \u001b[34m\u001b[1mLoading control grid from logs/ResnetConfig/CIFAR10/WanetBackdoor/wanet_backdoor.pt\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:51.080\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3100000023841858     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/acc_step       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3100000023841858     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.8737095594406128     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3100000023841858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/acc_step      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3100000023841858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8737095594406128    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scripts.eval_classifier(\n",
    "    scripts.EvalClassifierConfig(\n",
    "        path=path, data=data.BackdoorData(\n",
    "            original=Dataset(train=False),\n",
    "            backdoor=Backdoor(p_backdoor=0, p_noise=1),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results will also have been stored to `logs/demo/classifier/metrics.json` if we want to process them further (e.g. to compare many runs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test/loss': 1.8737095594406128, 'test/acc_step': 0.3100000023841858, 'test/acc_epoch': 0.3100000023841858}]\n"
     ]
    }
   ],
   "source": [
    "with open(path / \"eval.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a backdoor detector\n",
    "We'll train a very simple detector using the Mahalanobis distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbstractionDetectorConfig(train=TrainConfig(num_epochs=10, batch_size=128, max_batch_size=2048, optimizer=OptimizerConfig(name='adam', lr=0.001), num_workers=0, pin_memory=True, max_steps=-1, check_val_every_n_epoch=1, pbar=False, log_every_n_steps=None, wandb=False, devices='auto', accelerator='auto', precision=32, monitor_device_stats=False, profiler=None), abstraction=LocallyConsistentAbstractionConfig(size_reduction=4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectors.AbstractionDetectorConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-21 18:00:55.667\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mGenerating new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:55.669\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:55.677\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.utils.scripts\u001b[0m:\u001b[36mload_config\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mLoading config 'train_data' from logs/ResnetConfig/CIFAR10/WanetBackdoor\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:55.697\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:55.698\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-21 18:00:56.445\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.utils.scripts\u001b[0m:\u001b[36mload_config\u001b[0m:\u001b[36m55\u001b[0m - \u001b[34m\u001b[1mLoading config 'model' from logs/ResnetConfig/CIFAR10/WanetBackdoor\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:56.465\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "\u001b[32m2024-02-21 18:00:56.466\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mcupbearer.data.backdoors\u001b[0m:\u001b[36mcontrol_grid\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mSetting new control grid for warping field.\u001b[0m\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "scripts.train_detector(\n",
    "    scripts.TrainDetectorConfig(\n",
    "        path=path / \"lca\",\n",
    "        task=tasks.BackdoorDetection(\n",
    "            # We pass in the path of the trained classifier, as well as what backdoor\n",
    "            # to use. The backdoor is the same one we used for training in this case,\n",
    "            # we could also have stored that.\n",
    "            path=path,\n",
    "            backdoor=Backdoor(),\n",
    "        ),\n",
    "        detector=detectors.MahalanobisConfig(),\n",
    "        #detector=detectors.AbstractionDetectorConfig(\n",
    "        #    train=utils.TrainConfig(\n",
    "        #        num_workers=4,\n",
    "        #        num_epochs=10,\n",
    "        #        optimizer=utils.OptimizerConfig(\n",
    "        #            lr=0.001,\n",
    "        #        ),\n",
    "        #    )\n",
    "        #),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this was a trivial detection task. As an ablation, we can test whether the detector specifically flags backdoored inputs as anomalous, or just anything out of distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.eval_detector(\n",
    "    scripts.EvalDetectorConfig(\n",
    "        path=Path(\"logs/demo/detector\"),\n",
    "        task=tasks.CustomTask(\n",
    "            # TODO: this won't actually be used, plausibly Tasks should be split better\n",
    "            # into their training and test data.\n",
    "            train_data=data.MNIST(),\n",
    "            # Our anomalous data is the backdoor data from above, except we use the\n",
    "            # MNIST test split.\n",
    "            anomalous_data=data.BackdoorData(\n",
    "                original=data.MNIST(train=False),\n",
    "                backdoor=data.CornerPixelBackdoor(),\n",
    "            ),\n",
    "            # Our normal data is MNIST with added noise, this makes the images OOD\n",
    "            # but they shouldn't be mechanistically anomalous.\n",
    "            normal_test_data=data.MNIST(\n",
    "                train=False,\n",
    "                transforms={\n",
    "                    \"to_tensor\": data.ToTensor(),\n",
    "                    \"noise\": data.GaussianNoise(0.3),\n",
    "                },\n",
    "            ),\n",
    "            model=models.StoredModel(Path(\"logs/demo/classifier\")),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, adding noise did make the images quite a bit more \"anomalous\" according to our detector (the blue histogram has shifted to the right to higher anomaly scores). But we still have a very clear separation between these \"merely noisy\" inputs and the backdoored inputs. (This is a very easy to detect backdoor.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
